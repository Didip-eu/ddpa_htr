{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18a46bd9-5cc8-45a2-81ac-a0a6eea4fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Callable\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.v2 import ToTensor, Compose\n",
    "from torchvision.datasets import VisionDataset\n",
    "\n",
    "sys.path.append('..')\n",
    "from libs import list_utils as lu\n",
    "from libs import transforms as tsf\n",
    "from libs import seglib, charters_htr, metrics\n",
    "from model_htr import HTR_Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087639a-75e4-46d4-b93c-82e53c686973",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "* ensure that lines are concatenated in reading order (write a utility that may detect discrepancy between line ids and reading order)\n",
    "* filter GT transcriptions before aligning\n",
    "* performance measure: complete, with confusion matrix and F1, on large number of manuscripts\n",
    "* compare results with alignment based on edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcdcd69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InferenceDataset( VisionDataset ):\n",
    "\n",
    "    def __init__(self, img_path: Union[str,Path],\n",
    "                 segmentation_data: Union[str,Path],\n",
    "                 transform: Callable=None,\n",
    "                 padding_style=None) -> None:\n",
    "        \"\"\" A minimal dataset class for inference on a single charter (no transcription in the sample).\n",
    "\n",
    "        Args:\n",
    "            img_path (Union[Path,str]): charter image path\n",
    "\n",
    "            segmentation_data (Union[Path, str]): segmentation metadata (XML or JSON)\n",
    "            \n",
    "            transform (Callable): Image transform.\n",
    "\n",
    "            padding_style (str): How to pad the bounding box around the polygons, when \n",
    "                building the initial, raw dataset (before applying any transform):\n",
    "                + 'median'= polygon's median value,\n",
    "                + 'noise' = random noise,\n",
    "                + 'zero'= 0-padding, \n",
    "                + None (default) = no padding, i.e. raw bounding box\n",
    "        \"\"\"\n",
    "\n",
    "        trf = transform if transform else ToTensor()\n",
    "        super().__init__(root, transform=trf )\n",
    "\n",
    "        img_path = Path( img_path ) if type(img_path) is str else img_path\n",
    "        segmentation_data = Path( segmentation_data ) if type(segmentation_data) is str else segmentation_data\n",
    "\n",
    "        # extract line images: functions line_images_from_img_* return tuples (<line_img_hwc>: np.ndarray, <mask_hwc>: np.ndarray)\n",
    "        line_extraction_func = seglib.line_images_from_img_json_files if segmentation_data.suffix == '.json' else seglib.line_images_from_img_xml_files\n",
    "\n",
    "        line_padding_func = lambda x, m, channel_dim=2: x # by default, identity function\n",
    "        if padding_style == 'noise':\n",
    "            line_padding_func = tsf.bbox_noise_pad\n",
    "        elif padding_style == 'median':\n",
    "            line_padding_func = tsf.bbox_median_pad\n",
    "        elif padding_style == 'zero':\n",
    "            line_padding_func = tsf.bbox_zero_pad\n",
    "        print(line_padding_func)\n",
    "\n",
    "        self.data = []\n",
    "\n",
    "        for (img_hwc, mask_hwc) in line_extraction_func( img_path, segmentation_data ):\n",
    "            mask_hw = mask_hwc[:,:,0]\n",
    "            self.data.append( { 'img': line_padding_func( img_hwc, mask_hw, channel_dim=2 ), #tsf.bbox_median_pad( img_hwc, mask_hw, channel_dim=2 ), \n",
    "                                'height':img_hwc.shape[0],\n",
    "                                'width': img_hwc.shape[1],\n",
    "                               } )\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        sample = self.data[index].copy()\n",
    "        #logger.debug(f\"type(sample['img'])={type(sample['img'])} with shape= {sample['img'].shape}\" )\n",
    "        return self.transform( sample )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2ac60a-2e43-42e0-a620-c6f47290ef85",
   "metadata": {},
   "source": [
    "## Collect data to be aligned\n",
    "\n",
    "### Predicted transcription on charter image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6014848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/.pyenv/versions/3.8.19/lib/python3.8/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function bbox_median_pad at 0x7c329fcff430>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/graz/htr/vre/ddpa_htr/notebooks/../model_htr.py:255: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(file_name, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "# Get predicted lines, from img + segmentation file\n",
    "root = Path('.')\n",
    "\n",
    "collection_path = Path('/home/nicolas/tmp/data/fsdb_work/fsdb_sample/COLLECTIONS')\n",
    "img_path = collection_path.joinpath('586c0318ce423a882dac8411c6c61978/869b3709dd67347d9d243bef546a8f2c/c87b4566ac286b5ad58fa4fe1c60eb2a.img.jpg')\n",
    "segmentation_file_path = collection_path.joinpath('586c0318ce423a882dac8411c6c61978/869b3709dd67347d9d243bef546a8f2c/c87b4566ac286b5ad58fa4fe1c60eb2a.lines.gt.json')\n",
    "\n",
    "dataset = InferenceDataset( img_path, segmentation_file_path,\n",
    "                          transform = Compose([ ToTensor(),\n",
    "                                                tsf.ResizeToHeight(128,2048),\n",
    "                                                tsf.PadToWidth(2048),]),\n",
    "                          padding_style='median')\n",
    "model = HTR_Model.load('../model_koenigsfelden+nuremberg_letterbooks-2014.12.15.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eaec6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for line, sample in enumerate(DataLoader(dataset,batch_size=1)):\n",
    "    predicted_strings, line_scores = model.inference_task( sample['img'], sample['width'])\n",
    "    predictions.append({'line_id': line, 'transcription': predicted_strings[0], 'scores': lu.flatten(line_scores.tolist())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3783af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions_pred, scores = ( [ l[k] for l in predictions] for k in ('transcription', 'scores'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a5025b8-fb82-4b90-82e9-9d1d3c7f7ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wir, Leupolt von gots gnaden hertzog ze O?sterreich, ze Steyr, ze Kernden und ze Krain, graf ze Tyrol et?u0020cetera, mbieten den erbern, geist-',\n",
       " 'lichen, unsern lieben, andechtigen, dem provincial . . dem custer dem sichter und allen andern geistlichen amptluten minner',\n",
       " 'bruder ordens, die des klosters ze Kunigsveld gewaltig sind, gegenwurtigen und kumftigen, den diser brief getzaigt wirt, uns',\n",
       " 'gnad und alles gu?t. . wir bitten er alle und ewer yeglichen besunder und begern auch ernstlich, daz ir erun fleiz und ernste',\n",
       " 'dartzu keret, damit das egenanten kloster unster stift in geistlicher zu?chtr, ordnung und fride beleiben und bestande welhe kloster-',\n",
       " 'frowen daselbs sich aber dawider mit frevel, setzten und darinn nicht gehorsam sein wolten, daz ir die denn straffet nach eiers',\n",
       " 'ordens gesetz und rechten und dawan derselben klosterfrowen adel oder wer frunde nicht schonet. . davon emphelhen wir',\n",
       " 'dem edeln, unserm lieben oheini, gras Hannsen von Habspurg, unserm lantvo?gte oder wer ye ze den zeiten unser lantvogt ist, .',\n",
       " 'und wellen auch ernstlich, daz er den egenanten prelaten des klosters beholfen sey . und sy ouch halte und schirme . die straffung',\n",
       " 'ze volfu?ren, als oben geschriben stat. . wer aber, daz dieselben prelaten vorchtsam oder saumig weren, das ze tu?n, damit das',\n",
       " 'obgenanten kloster in smech oder unordnung keme, das wo?lten wir hintz in bekomen und unser ungnad, swerlich darumb an sy legen',\n",
       " 'wan wir in von unsern wegen gantzen und vollen gewalt geben in allen sachen ze tu?n und ze handeln, damit die obgenanten',\n",
       " 'klosterfrowen bey geistlicher zucht und ordnung und vor weltlichem ungelimphen beleiben und behu?tet mugen werden.',\n",
       " 'geben ze Gann an montag vor sand U?lreichs tag, . anno domini millesimo Grecensis  nonagesimo octavo.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48feb457-c512-4694-a01d-d7f772a02438",
   "metadata": {},
   "source": [
    "### Ground truth transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "324ad6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT transcriptions = 14\n"
     ]
    }
   ],
   "source": [
    "# Get GT transcriptions\n",
    "page_path = re.sub(r'\\..+$', r'.xml', str(img_path))\n",
    "samples = charters_htr.ChartersDataset.extract_lines_from_pagexml(page_path)\n",
    "transcriptions_gt = [ s['transcription'] for s in samples]\n",
    "print(\"GT transcriptions =\", len(transcriptions_gt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063622c-05b9-4d2f-965a-47af89f61479",
   "metadata": {},
   "source": [
    "## Computing alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "860d7f6c-66d2-4ca9-841b-44f7a1524012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaks in predicted strings = 13\n"
     ]
    }
   ],
   "source": [
    "# concatenate transcriptions for each set\n",
    "transcriptions_gt_cat = ''.join(transcriptions_gt)\n",
    "transcriptions_pred_cat = ''.join(transcriptions_pred)\n",
    "# compute positions of line breaks in pred. (it is an offset in the string. Eg. 12 means 'after substring [0..11]\n",
    "line_break_offsets_pred = list(itertools.accumulate( len(tr) for tr in transcriptions_pred ))[:-1]\n",
    "line_break_offsets_pred\n",
    "print(\"Breaks in predicted strings =\", len(line_break_offsets_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6e020ed6-b086-4382-b6a5-6706bb96948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "align_pred, align_gt = metrics.align_lcs( transcriptions_pred_cat, transcriptions_gt_cat )\n",
    "#''.join([ transcriptions_pred_cat[i] for i in align_pred ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9bda0868-ad8b-410c-b183-6788d938e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l b g d f o d u z o w k g Breaks in segmented GT strings = 13\n"
     ]
    }
   ],
   "source": [
    "def closest( tbl, val ):\n",
    "    for i in range(val):\n",
    "        if val-i in tbl.keys():\n",
    "            #print(\"Closest=\",val-i, end=\" \")\n",
    "            return val-i\n",
    "            \n",
    "lcs_translation_table = { p:g for (p,g) in zip( align_pred, align_gt ) }\n",
    "#transcriptions_gt_segmented = []\n",
    "#last_offset = 0\n",
    "line_break_offsets_gt_segmented = []\n",
    "for offset in line_break_offsets_pred:\n",
    "    print(transcriptions_pred_cat[offset], end=' ')\n",
    "    # find closest index in LCS-pred. Before or after? Depends on how\n",
    "    # likely characters at SOL and EOL respectively are included in the LCS.\n",
    "    lcs_i_pred = closest( lcs_translation_table, offset-1)\n",
    "    lcs_i_gt = lcs_translation_table[lcs_i_pred]\n",
    "    line_break_offsets_gt_segmented.append( lcs_i_gt+1 )\n",
    "print(\"Breaks in segmented GT strings =\", len(line_break_offsets_gt_segmented))\n",
    "\n",
    "def split_on_offsets( string, offsets ):\n",
    "    if not offsets:\n",
    "        return string\n",
    "    if not string:\n",
    "        return []\n",
    "    output = []\n",
    "    last_offset = 0\n",
    "    for i in offsets:\n",
    "        output.append( string[last_offset:i] )\n",
    "        last_offset = i\n",
    "    output.append( string[last_offset:] )\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "399ece58-2c06-4ecc-b54f-06a1d5e0a5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 14\n"
     ]
    }
   ],
   "source": [
    "'@'.join(transcriptions_pred)\n",
    "print(\"Length:\", len( transcriptions_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4e7a2070-3611-4e34-a7d2-eefa04870bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 14\n"
     ]
    }
   ],
   "source": [
    "gt_segmented = split_on_offsets(transcriptions_gt_cat, line_break_offsets_gt_segmented)\n",
    "'@'.join( gt_segmented )\n",
    "print(\"Length:\", len( gt_segmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "41f4f185-52cb-464c-8177-378894999382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#''.join([transcriptions_pred_cat[i] for i in align_pred ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5648fad6-7d29-4ef1-aa73-87052b9c4402",
   "metadata": {},
   "source": [
    "## Evaluation IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e8f6719b-20f3-4ed7-b510-206162dfee7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wir, Leupolt, von gots gnaden hertzog ze Oͤsterreich, ze Steyr, ze Keͣrnden und ze Krain, graf ze Tyrol et\\\\u0020cetera, ✳ embieten den erbern, geist¬', 'lichen, ùnsern lieben, andêchtigen, ✳ dem provincial, ✳ dem custer, ✳ dem bichter und allen andern geistlichen amptlùten, Minner¬', 'bruder ordens, die des klosters ze Kùnigsveld gewaltig sind, gegenwùrtigen und kùmftigen, den diser brief getzaigt wirt, ùnser', 'gnad und alles guͤt. ✳ wir bitten ew alle und ewr yeglichen besunder und begern auch ernstlich, daz ir ewern fleizz und ernste', 'dartzu keret, damit das egenante kloster, unserr stift, in geistlicher zucht, ordnung und fride beleibe und bestande. ✳ welhe kloster¬', 'frowen daselbs sich aber dawider mit freͣvel setzten und darinn nicht gehorsam sein wolten, daz ir die denn straffet nach ewers', 'ordens gesetz und rechten ✳ und daran derselben klosterfrowen adel oder irer freunde nicht schonet. ✳ davon emphelhen wir', 'dem edeln, unserm lieben oͤheim, graf Hannsen von Habspurg, unserm lantvogte, oder wer ye ze den zeiten ùnser lantvogt ist, ✳', 'und wellen auch ernstlich, daz er den egenanten prelaten des klosters beholfen sey ✳ und sy auch halte und schirme, die straffung', 'ze volfùren, als oben geschriben stat. ✳ weͣr aber, daz dieselben prelaten vorchtsam oder sauͤmig weͣren, das ze tuͤn, damit das', 'obgenante kloster in smeͣch oder unordnung keͣme, das wolten wir hintz in bekomen und unser ungnad sweͣrlich darumb an sy legen,', 'wan wir in von ùnsern wegen gantzen und vollen gewalt geben, in allen sachen ze tuͤn und ze handeln, damit die obgenanten', 'klosterfrowen bey geistlicher zucht und ordnung ✳ und vor weltlichem ungelimphen beleiben und behuͤtet mùgen werden. ✳', 'geben ze Tann, an montag vor sand Ulreichs tag, anno domini millesimo trecentesimo nonagesimo octavo. ✳'] len= 14\n"
     ]
    }
   ],
   "source": [
    "print(transcriptions_gt, \"len=\", len(transcriptions_gt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ece48e0c-7dac-42f8-8200-5939d8d8bac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wir, Leupolt, von gots gnaden hertzog ze Oͤsterreich, ze Steyr, ze Keͣrnden und ze Krain, graf ze Tyrol et\\\\u0020cetera, ✳ embieten den erbern, geist', '¬lichen, ùnsern lieben, andêchtigen, ✳ dem provincial, ✳ dem custer, ✳ dem bichter und allen andern geistlichen amptlùten, Minner', '¬bruder ordens, die des klosters ze Kùnigsveld gewaltig sind, gegenwùrtigen und kùmftigen, den diser brief getzaigt wirt, ùns', 'ergnad und alles guͤt. ✳ wir bitten ew alle und ewr yeglichen besunder und begern auch ernstlich, daz ir ewern fleizz und ernste', 'dartzu keret, damit das egenante kloster, unserr stift, in geistlicher zucht, ordnung und fride beleibe und bestande. ✳ welhe kloster', '¬frowen daselbs sich aber dawider mit freͣvel setzten und darinn nicht gehorsam sein wolten, daz ir die denn straffet nach ewers', 'ordens gesetz und rechten ✳ und daran derselben klosterfrowen adel oder irer freunde nicht schonet. ✳ davon emphelhen wir', 'dem edeln, unserm lieben oͤheim, graf Hannsen von Habspurg, unserm lantvogte, oder wer ye ze den zeiten ùnser lantvogt ist, ', '✳und wellen auch ernstlich, daz er den egenanten prelaten des klosters beholfen sey ✳ und sy auch halte und schirme, die straffung', 'ze volfùren, als oben geschriben stat. ✳ weͣr aber, daz dieselben prelaten vorchtsam oder sauͤmig weͣren, das ze tuͤn, damit das', 'obgenante kloster in smeͣch oder unordnung keͣme, das wolten wir hintz in bekomen und unser ungnad sweͣrlich darumb an sy legen', ',wan wir in von ùnsern wegen gantzen und vollen gewalt geben, in allen sachen ze tuͤn und ze handeln, damit die obgenanten', 'klosterfrowen bey geistlicher zucht und ordnung ✳ und vor weltlichem ungelimphen beleiben und behuͤtet mùgen werden.', ' ✳geben ze Tann, an montag vor sand Ulreichs tag, anno domini millesimo trecentesimo nonagesimo octavo. ✳'] len= 14\n"
     ]
    }
   ],
   "source": [
    "print(gt_segmented, \"len=\", len(gt_segmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c1181924-7efa-4991-a4f3-adfa1676d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists have 14 and 14 elements, respectively.\n",
      "IoU = 0.9932885906040269\n",
      "IoU = 0.9846153846153847\n",
      "IoU = 0.9763779527559056\n",
      "IoU = 0.984375\n",
      "IoU = 0.9925373134328358\n",
      "IoU = 0.9921875\n",
      "IoU = 1.0\n",
      "IoU = 0.992\n",
      "IoU = 0.9923076923076923\n",
      "IoU = 1.0\n",
      "IoU = 0.9921875\n",
      "IoU = 0.9918032786885246\n",
      "IoU = 0.9830508474576272\n",
      "IoU = 0.9809523809523809\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (chars shared) / Union - segmentation is done on encoded strings, for easy set computation\n",
    "line_break_offsets_gt = list(itertools.accumulate( len(tr) for tr in transcriptions_gt ))[:-1]\n",
    "positions = list(range(len(transcriptions_gt_cat)))\n",
    "gt_sets =  [ set(s) for s in split_on_offsets( positions, line_break_offsets_gt )]\n",
    "gt_segmented_sets = [ set(s) for s in split_on_offsets(positions, line_break_offsets_gt_segmented)]\n",
    "\n",
    "print('Lists have {} and {} elements, respectively.'.format( len(transcriptions_gt), len(gt_segmented_sets)))\n",
    "for l in range(len(gt_sets)):\n",
    "    intersection = gt_sets[l].intersection(gt_segmented_sets[l])\n",
    "    union = gt_sets[l].union(gt_segmented_sets[l])\n",
    "    print(\"IoU =\", len(intersection)/len(union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb7a35-f7e3-4bfe-866e-4b874896b171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
